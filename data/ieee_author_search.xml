<?xml version="1.0" encoding="UTF-8"?>

<root>

<totalfound>37</totalfound>

<totalsearched>3873373</totalsearched>

<document>

<rank>1</rank>

<title><![CDATA[Ad hoc grid security infrastructure]]></title>

<authors><![CDATA[Amin, K.;  von Laszewski, G.;  Sosonkin, M.;  Mikler, A.R.;  Hategan, M.]]></authors>

<affiliations><![CDATA[Math. & Comput. Sci. Div., Argonne Nat. Lab., IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Java]]></term>

<term><![CDATA[XML]]></term>

<term><![CDATA[authorisation]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[message authentication]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Authorization]]></term>

<term><![CDATA[Centralized control]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Computer security]]></term>

<term><![CDATA[Environmental management]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Java]]></term>

<term><![CDATA[Mathematics]]></term>

<term><![CDATA[National security]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Grid Computing, 2005. The 6th IEEE/ACM International Workshop on]]></pubtitle>

<punumber><![CDATA[10354]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2005]]></py>

<spage><![CDATA[8 pp.]]></spage>

<abstract><![CDATA[This paper describes an ad hoc grid security infrastructure developed as a part of the Java CoG Kit project. It supports several requirements specific to the sporadic nature of ad hoc grids. It focuses on identity management, identity verification, and authorization control in spontaneous grid collaborations without pre-established policies or environments. It adopts established community standards, with modifications where needed. This paper also discusses the integration of the ad hoc grid security infrastructure in an ad hoc grid implementation. The implementation supports secure collaboration in ad hoc grids using commodity technologies such as the Java CoG Kit, JXTA, GSI, and XACML.]]></abstract>

<isbn><![CDATA[0-7803-9492-5]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1542726]]></arnumber>

<doi><![CDATA[10.1109/GRID.2005.1542726]]></doi>

<publicationId><![CDATA[1542726]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1542726&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542726]]></pdf>

</document>

<document>

<rank>2</rank>

<title><![CDATA[A fault detection service for wide area distributed computations]]></title>

<authors><![CDATA[Stelling, P.;  Foster, I.;  Kesselman, C.;  Lee, C.;  von Laszewski, G.]]></authors>

<affiliations><![CDATA[Aerosp. Corp., El Segundo, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer network reliability]]></term>

<term><![CDATA[fault diagnosis]]></term>

<term><![CDATA[system monitoring]]></term>

<term><![CDATA[wide area networks]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer networks]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Distributed computing]]></term>

<term><![CDATA[Fault detection]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Mathematics]]></term>

<term><![CDATA[Resource management]]></term>

</thesaurusterms>

<pubtitle><![CDATA[High Performance Distributed Computing, 1998. Proceedings. The Seventh International Symposium on]]></pubtitle>

<punumber><![CDATA[5737]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[1998]]></py>

<spage><![CDATA[268]]></spage>

<epage><![CDATA[278]]></epage>

<abstract><![CDATA[The potential for faults in distributed computing systems is a significant complicating factor for application developers. While a variety of techniques exist for detecting and correcting faults, the implementation of these techniques in a particular context can be difficult. Hence, we propose a fault detection service designed to be incorporated, in a modular fashion, into distributed computing systems, tools, or applications. This service uses well-known techniques based on unreliable fault detectors to detect and report component failure, while allowing the user to tradeoff timeliness of reporting against false positive rates. We describe the architecture of this service, report on experimental results that quantify its cost and accuracy, and describe its use in two applications, monitoring the status of system components of the GUSTO computational grid testbed and as part of the NetSolve network-enabled numerical solver]]></abstract>

<issn><![CDATA[1082-8907]]></issn>

<isbn><![CDATA[0-8186-8579-4]]></isbn>

<arnumber><![CDATA[709981]]></arnumber>

<doi><![CDATA[10.1109/HPDC.1998.709981]]></doi>

<publicationId><![CDATA[709981]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=709981&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=709981]]></pdf>

</document>

<document>

<rank>3</rank>

<title><![CDATA[Abstract Image Management and Universal Image Registration for Cloud and HPC Infrastructures]]></title>

<authors><![CDATA[Diaz, J.;  von Laszewski, G.;  Fugang Wang;  Fox, G.]]></authors>

<affiliations><![CDATA[Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cloud computing]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[security of data]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Abstracts]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Image registration]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Security]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Cloud Computing (CLOUD), 2012 IEEE 5th International Conference on]]></pubtitle>

<punumber><![CDATA[6253102]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2012]]></py>

<spage><![CDATA[463]]></spage>

<epage><![CDATA[470]]></epage>

<abstract><![CDATA[Cloud computing has become an important driver for delivering infrastructure as a service (IaaS) to users with on-demand requests for customized environments and sophisticated software stacks. Within the FutureGrid (FG) project, we offer different IaaS frameworks as well as high performance computing infrastructures by allowing users to explore them as part of the FG testbed. To ease the use of these infrastructures, as part of performance experiments, we have designed an image management framework, which allows us to create user defined software stacks based on abstract image management and uniform image registration. Consequently, users can create their own customized environments very easily. The complex processes of the underlying infrastructures are managed by our sophisticated software tools and services. Besides being able to manage images for IaaS frameworks, we also allow the registration and deployment of images onto bare-metal by the user. This level of functionality is typically not offered in a HPC (high performance computing) infrastructure. However, our approach provides users with the ability to create their own environments changing the paradigm of administrator-controlled dynamic provisioning to user-controlled dynamic provisioning, which we also call raining. Thus, users obtain access to a testbed with the ability to manage state-of-the-art software stacks that would otherwise not be supported in typical compute centers. Security is also considered by vetting images before they are registered in a infrastructure. In this paper, we present the design of our image management framework and evaluate two of its major components. This includes the image creation and image registration. Our design and implementation can support the current FG user community interested in such capabilities.]]></abstract>

<issn><![CDATA[2159-6182]]></issn>

<isbn><![CDATA[978-1-4673-2892-0]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6253539]]></arnumber>

<doi><![CDATA[10.1109/CLOUD.2012.94]]></doi>

<publicationId><![CDATA[6253539]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6253539&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6253539]]></pdf>

</document>

<document>

<rank>4</rank>

<title><![CDATA[A directory service for configuring high-performance distributed computations]]></title>

<authors><![CDATA[Fitzgerald, S.;  Foster, I.;  Kesselman, C.;  von Laszewski, G.;  Smith, W.;  Tuecke, S.]]></authors>

<affiliations><![CDATA[Inf. Sci. Inst., Univ. of Southern California, Marina del Rey, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[performance evaluation]]></term>

<term><![CDATA[protocols]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Access protocols]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer networks]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Distributed computing]]></term>

<term><![CDATA[IP networks]]></term>

<term><![CDATA[Mathematics]]></term>

<term><![CDATA[Metacomputing]]></term>

<term><![CDATA[TCPIP]]></term>

</thesaurusterms>

<pubtitle><![CDATA[High Performance Distributed Computing, 1997. Proceedings. The Sixth IEEE International Symposium on]]></pubtitle>

<punumber><![CDATA[4902]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[1997]]></py>

<spage><![CDATA[365]]></spage>

<epage><![CDATA[375]]></epage>

<abstract><![CDATA[High-performance execution in distributed computing environments often requires careful selection and configuration not only of computers, networks, and other resources but also of the protocols and algorithms used by applications. Selection and configuration in turn require access to accurate, up-to-date information on the structure and state of available resources. Unfortunately no standard mechanism exists for organizing or accessing such information. Consequently different tools and applications adopt ad hoc mechanisms, or they compromise their portability and performance by using default configurations. We propose a Metacomputing Directory Service that provides efficient and scalable access to diverse, dynamic, and distributed information about resource structure and state. We define an extensible data model to represent required information and present a scalable, high-performance, distributed implementation. The data representation and application programming interface are adopted from the Lightweight Directory Access Protocol; the data model and implementation are new. We use the Globus distributed computing toolkit to illustrate how this directory service enables the development of more flexible and efficient distributed computing services and applications]]></abstract>

<issn><![CDATA[1082-8907]]></issn>

<isbn><![CDATA[0-8186-8117-9]]></isbn>

<arnumber><![CDATA[626445]]></arnumber>

<doi><![CDATA[10.1109/HPDC.1997.626445]]></doi>

<publicationId><![CDATA[626445]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=626445&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=626445]]></pdf>

</document>

<document>

<rank>5</rank>

<title><![CDATA[Towards Thermal Aware Workload Scheduling in a Data Center]]></title>

<authors><![CDATA[Lizhe Wang;  von Laszewski, G.;  Dayal, J.;  Xi He;  Younge, A.J.;  Furlani, T.R.]]></authors>

<affiliations><![CDATA[Service Oriented Cyberinfrastructure Lab., Rochester Inst. of Technol., Rochester, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer centres]]></term>

<term><![CDATA[cooling]]></term>

<term><![CDATA[power consumption]]></term>

<term><![CDATA[power engineering computing]]></term>

<term><![CDATA[scheduling]]></term>

<term><![CDATA[software maintenance]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Cooling]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Energy consumption]]></term>

<term><![CDATA[Heat transfer]]></term>

<term><![CDATA[Processor scheduling]]></term>

<term><![CDATA[Scheduling algorithm]]></term>

<term><![CDATA[Temperature]]></term>

<term><![CDATA[Thermal management]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Pervasive Systems, Algorithms, and Networks (ISPAN), 2009 10th International Symposium on]]></pubtitle>

<punumber><![CDATA[5379703]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2009]]></py>

<spage><![CDATA[116]]></spage>

<epage><![CDATA[122]]></epage>

<abstract><![CDATA[High density blade servers are a popular technology for data centers, however, the heat dissipation density of data centers increases exponentially. There is strong evidence to support that high temperatures of such data centers will lead to higher hardware failure rates and thus an increase in maintenance costs. Improperly designed or operated data centers may either suffer from overheated servers and potential system failures, or from overcooled systems, causing extraneous utilities cost. Minimizing the cost of operation (utilities, maintenance, device upgrade and replacement) of data centers is one of the key issues involved with both optimizing computing resources and maximizing business outcome. This paper proposes an analytical model, which describes data center resources with heat transfer properties and workloads with thermal features. Then a thermal aware task scheduling algorithm is presented which aims to reduce power consumption and temperatures in a data center. A simulation study is carried out to evaluate the performance of the algorithm. Simulation results show that our algorithm can significantly reduce temperatures in data centers by introducing endurable decline in performance.]]></abstract>

<isbn><![CDATA[978-1-4244-5403-7]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5381947]]></arnumber>

<doi><![CDATA[10.1109/I-SPAN.2009.22]]></doi>

<publicationId><![CDATA[5381947]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5381947&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5381947]]></pdf>

</document>

<document>

<rank>6</rank>

<title><![CDATA[InfoGram: a grid service that supports both information queries and job execution]]></title>

<authors><![CDATA[von Laszewski, G.;  Gawor, J.;  Pena, C.J.;  Foster, I.]]></authors>

<affiliations><![CDATA[Argonne Nat. Lab., IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[distributed processing]]></term>

<term><![CDATA[information resources]]></term>

<term><![CDATA[processor scheduling]]></term>

<term><![CDATA[query processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Information security]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Project management]]></term>

<term><![CDATA[Protocols]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Resource management]]></term>

<term><![CDATA[Web services]]></term>

<term><![CDATA[Wire]]></term>

</thesaurusterms>

<pubtitle><![CDATA[High Performance Distributed Computing, 2002. HPDC-11 2002. Proceedings. 11th IEEE International Symposium on]]></pubtitle>

<punumber><![CDATA[7999]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2002]]></py>

<spage><![CDATA[333]]></spage>

<epage><![CDATA[342]]></epage>

<abstract><![CDATA[The research described in this paper is performed as part of the Globus Project. It introduces a new grid service called InfoGram that combines the ability of serving as information service and as a job execution service. Previously, both services were architected and implemented within the Globus Toolkit as two different services with different wire protocols. Our service demonstrates a significant simplification of the architecture while treating job submissions and information queries alike. The advantage of our service is that it provides backwards compatibility to existing grid services, while at the same time providing forwards compatibility to the emerging Web services world. Part of the work conducted within this effort is already reused by the current open grid services architecture prototype implementation.]]></abstract>

<issn><![CDATA[1082-8907]]></issn>

<isbn><![CDATA[0-7695-1686-6]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1029933]]></arnumber>

<doi><![CDATA[10.1109/HPDC.2002.1029933]]></doi>

<publicationId><![CDATA[1029933]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1029933&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1029933]]></pdf>

</document>

<document>

<rank>7</rank>

<title><![CDATA[The Astrophysics Simulation Collaboratory: a science portal enabling community software development]]></title>

<authors><![CDATA[Russell, M.;  Allen, G.;  Daues, G.;  Foster, I.;  Seidel, E.;  Novotny, J.;  Shalf, J.;  von Laszewski, G.]]></authors>

<affiliations><![CDATA[Chicago Univ., IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[astronomy computing]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[information resources]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Astrophysics]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Collaborative software]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer interfaces]]></term>

<term><![CDATA[Distributed computing]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Portals]]></term>

<term><![CDATA[Problem-solving]]></term>

<term><![CDATA[Programming]]></term>

</thesaurusterms>

<pubtitle><![CDATA[High Performance Distributed Computing, 2001. Proceedings. 10th IEEE International Symposium on]]></pubtitle>

<punumber><![CDATA[7513]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2001]]></py>

<spage><![CDATA[207]]></spage>

<epage><![CDATA[215]]></epage>

<abstract><![CDATA[Grid Portals, based on standard Web technologies, are emerging as important and useful user interfaces to computational and data grids. Grid portals enable virtual organizations, comprised of distributed researchers to collaborate and access resources more efficiently and seamlessly. The Astrophysics Simulation Collaboratory (ASC) Grid Portal provides a framework to enable researchers in the field of numerical relativity to study astrophysical phenomenon by making use of the Cactus computational toolkit. We examine user requirements and describe the design and implementation of the ASC Grid Portal]]></abstract>

<issn><![CDATA[1082-8907]]></issn>

<isbn><![CDATA[0-7695-1296-8]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[945190]]></arnumber>

<doi><![CDATA[10.1109/HPDC.2001.945190]]></doi>

<publicationId><![CDATA[945190]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=945190&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=945190]]></pdf>

</document>

<document>

<rank>8</rank>

<title><![CDATA[GridAnt: a client-controllable grid workflow system]]></title>

<authors><![CDATA[Amin, K.;  von Laszewski, G.;  Hategan, M.;  Zaluzec, N.J.;  Hampton, S.;  Rossi, A.]]></authors>

<affiliations><![CDATA[Argonne Nat. Lab., IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[workflow management software]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Business]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Dynamic programming]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Open source software]]></term>

<term><![CDATA[Pattern analysis]]></term>

<term><![CDATA[Workflow management software]]></term>

</thesaurusterms>

<pubtitle><![CDATA[System Sciences, 2004. Proceedings of the 37th Annual Hawaii International Conference on]]></pubtitle>

<punumber><![CDATA[8934]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2004]]></py>

<spage><![CDATA[10 pp.]]></spage>

<abstract><![CDATA[Process management is an extremely important concept in both business and scientific communities. Several workflow management tools have been proposed in recent years offering advanced functionality in various domains. In the business world, workflow vendors offer commercial and customized solutions targeting specific users. In the scientific world, several open-source workflow management tools are freely available. However they are directed toward service aggregation rather than distributed process management. Little consideration is given to the needs of the client in terms of mapping the process flow of the client. In the grid community it is essential that the grid users have such a tool available enabling them to orchestrate complex work-flows on the fly without substantial help from the service providers. At the same time it is important that the grid user not be burdened with the intricacies of the workflow system. With the perspective of the grid user in mind, an extensible client-side workflow management system, called GridAnt, has been developed. This paper discusses the design principles, functionality, and application of the proposed GridAnt workflow manager.]]></abstract>

<isbn><![CDATA[0-7695-2056-1]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1265491]]></arnumber>

<doi><![CDATA[10.1109/HICSS.2004.1265491]]></doi>

<publicationId><![CDATA[1265491]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1265491&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1265491]]></pdf>

</document>

<document>

<rank>9</rank>

<title><![CDATA[Comparison of Multiple Cloud Frameworks]]></title>

<authors><![CDATA[von Laszewski, G.;  Diaz, J.;  Fugang Wang;  Fox, G.C.]]></authors>

<affiliations><![CDATA[Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cloud computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cloud computing]]></term>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Communities]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Servers]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Cloud Computing (CLOUD), 2012 IEEE 5th International Conference on]]></pubtitle>

<punumber><![CDATA[6253102]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2012]]></py>

<spage><![CDATA[734]]></spage>

<epage><![CDATA[741]]></epage>

<abstract><![CDATA[Today, many cloud Infrastructure as a Service(IaaS) frameworks exist. Users, developers, and administrators have to make a decision about which environment is best suited for them. Unfortunately, the comparison of such frameworks is difficult because either users do not have access to all of them or they are comparing the performance of such systems on different resources, which make it difficult to obtain objective comparisons. Hence, the community benefits from the availability of a testbed on which comparisons between the IaaS frameworks can be conducted. FutureGrid aims to offer a number of IaaS including Nimbus, Eucalyptus, OpenStack, and OpenNebula. One of the important features that FutureGrid provides is not only the ability to compare between IaaS frameworks, but also to compare them in regards to bare-metal and traditional high performance computing services. In this paper, we outline some of our initial findings by providing such a testbed. As one of our conclusions, we also present our work on making access to the various infrastructures on FutureGrid easier.]]></abstract>

<issn><![CDATA[2159-6182]]></issn>

<isbn><![CDATA[978-1-4673-2892-0]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6253573]]></arnumber>

<doi><![CDATA[10.1109/CLOUD.2012.104]]></doi>

<publicationId><![CDATA[6253573]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6253573&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6253573]]></pdf>

</document>

<document>

<rank>10</rank>

<title><![CDATA[Distance visualization: data exploration on the grid]]></title>

<authors><![CDATA[Foster, I.;  Insley, Joseph;  von Laszewski, G.;  Kesselman, C.;  Thiebaux, Marcus]]></authors>

<affiliations><![CDATA[Argonne Nat. Lab., IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data acquisition]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data reduction]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[natural sciences computing]]></term>

<term><![CDATA[online operation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Instruments]]></term>

<term><![CDATA[Linear particle accelerator]]></term>

<term><![CDATA[Microscopy]]></term>

<term><![CDATA[Satellites]]></term>

<term><![CDATA[Telescopes]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Computer]]></pubtitle>

<punumber><![CDATA[2]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[32]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[36]]></spage>

<epage><![CDATA[43]]></epage>

<abstract><![CDATA[Our increased ability to model and measure a wide variety of phenomena has left us awash in data. In the immediate future, the authors anticipate collecting data at the rate of terabytes per day from many classes of applications, including simulations running on teraFLOPS-class computers and experimental data produced by increasingly more sensitive and accurate instruments, such as telescopes, microscopes, particle accelerators and satellites. Generating or acquiring data is not an end in itself but a vehicle for obtaining insights. While data analysis and reduction have a role to play, in many situations we achieve understanding only when a human being interprets the data. Visualization has emerged as an important tool for extracting meaning from the large volumes of data that scientific instruments and simulations produce. The authors describe an online system that supports 3D tomographic image reconstruction-and subsequent collaborative analysis-of data from remote scientific instruments]]></abstract>

<issn><![CDATA[0018-9162]]></issn>

<arnumber><![CDATA[809249]]></arnumber>

<doi><![CDATA[10.1109/2.809249]]></doi>

<publicationId><![CDATA[809249]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=809249&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=809249]]></pdf>

</document>

<document>

<rank>11</rank>

<title><![CDATA[Design of the FutureGrid experiment management framework]]></title>

<authors><![CDATA[von Laszewski, G.;  Fox, G.C.;  Fugang Wang;  Younge, A.J.;  Kulshrestha, A.;  Pike, G.G.;  Smith, W.;  Vo&#x0308; ckler, J.;  Figueiredo, R.J.;  Fortes, J.;  Keahey, K.]]></authors>

<affiliations><![CDATA[Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cloud computing]]></term>

<term><![CDATA[grid computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Communities]]></term>

<term><![CDATA[Dynamic scheduling]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Home appliances]]></term>

<term><![CDATA[Middleware]]></term>

<term><![CDATA[Software]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Gateway Computing Environments Workshop (GCE), 2010]]></pubtitle>

<punumber><![CDATA[5668967]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[10]]></epage>

<abstract><![CDATA[FutureGrid provides novel computing capabilities that enable reproducible experiments while simultaneously supporting dynamic provisioning. This paper describes the FutureGrid experiment management framework to create and execute large scale scientific experiments for researchers around the globe. The experiments executed are performed by the various users of FutureGrid ranging from administrators to software developers and end users. The Experiment management framework will consist of software tools that record user and system actions to generate a reproducible set of tasks and resource configurations. Additionally, the experiment management framework can be used to share not only the experiment setup, but also performance information for the specific instantiation of the experiment. This makes it possible to compare a variety of experiment setups and analyze the impact Grid and Cloud software stacks have.]]></abstract>

<issn><![CDATA[2152-1085]]></issn>

<isbn><![CDATA[978-1-4244-9751-5]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5676126]]></arnumber>

<doi><![CDATA[10.1109/GCE.2010.5676126]]></doi>

<publicationId><![CDATA[5676126]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5676126&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5676126]]></pdf>

</document>

<document>

<rank>12</rank>

<title><![CDATA[FutureGrid Image Repository: A Generic Catalog and Storage System for Heterogeneous Virtual Machine Images]]></title>

<authors><![CDATA[Diaz, J.;  von Laszewski, G.;  Fugang Wang;  Younge, A.J.;  Fox, G.]]></authors>

<affiliations><![CDATA[Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cloud computing]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[meta data]]></term>

<term><![CDATA[operating systems (computers)]]></term>

<term><![CDATA[storage management]]></term>

<term><![CDATA[virtual machines]]></term>

<term><![CDATA[virtualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Catalogs]]></term>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Fault tolerance]]></term>

<term><![CDATA[Fault tolerant systems]]></term>

<term><![CDATA[Portals]]></term>

<term><![CDATA[Security]]></term>

<term><![CDATA[Software]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Cloud Computing Technology and Science (CloudCom), 2011 IEEE Third International Conference on]]></pubtitle>

<punumber><![CDATA[6132468]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2011]]></py>

<spage><![CDATA[560]]></spage>

<epage><![CDATA[564]]></epage>

<abstract><![CDATA[Future Grid (FG) is an experimental, high-performance test bed that supports HPC, cloud and grid computing experiments for both application and computer scientist. Future Grid includes the use of virtualization technology to allow the support of a wide range of operating systems in order to include a test bed for various cloud computing infrastructure as a service frameworks. Therefore, efficient management of a variety of virtual machine images becomes a key issue. Current cloud frameworks do not provide a way to manage images for different IaaS frameworks. They typically provide their own image repositories, but in general they do not allow us to store the needed metadata to handle other IaaS images. We present a generic catalog and image repository to store images of any type. Our image repository has a convenient interface that distinguishes image types. Therefore, it is not only useful for Future Grid, but also for any application that needs to manage images.]]></abstract>

<isbn><![CDATA[978-1-4673-0090-2]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6133194]]></arnumber>

<doi><![CDATA[10.1109/CloudCom.2011.85]]></doi>

<publicationId><![CDATA[6133194]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6133194&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6133194]]></pdf>

</document>

<document>

<rank>13</rank>

<title><![CDATA[Analysis of Virtualization Technologies for High Performance Computing Environments]]></title>

<authors><![CDATA[Younge, A.J.;  Henschel, R.;  Brown, J.T.;  von Laszewski, G.;  Qiu, J.;  Fox, G.C.]]></authors>

<affiliations><![CDATA[Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cloud computing]]></term>

<term><![CDATA[virtualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Benchmark testing]]></term>

<term><![CDATA[Cloud computing]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Linux]]></term>

<term><![CDATA[Virtual machine monitors]]></term>

<term><![CDATA[Virtual machining]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Cloud Computing (CLOUD), 2011 IEEE International Conference on]]></pubtitle>

<punumber><![CDATA[6008653]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2011]]></py>

<spage><![CDATA[9]]></spage>

<epage><![CDATA[16]]></epage>

<abstract><![CDATA[As Cloud computing emerges as a dominant paradigm in distributed systems, it is important to fully understand the underlying technologies that make Clouds possible. One technology, and perhaps the most important, is virtualization. Recently virtualization, through the use of hyper visors, has become widely used and well understood by many. However, there are a large spread of different hyper visors, each with their own advantages and disadvantages. This paper provides an in-depth analysis of some of today's commonly accepted virtualization technologies from feature comparison to performance analysis, focusing on the applicability to High Performance Computing environments using Future Grid resources. The results indicate virtualization sometimes introduces slight performance impacts depending on the hyper visor type, however the benefits of such technologies are profound and not all virtualization technologies are equal. From our experience, the KVM hyper visor is the optimal choice for supporting HPC applications within a Cloud infrastructure.]]></abstract>

<issn><![CDATA[2159-6182]]></issn>

<isbn><![CDATA[978-1-4577-0836-7]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6008687]]></arnumber>

<doi><![CDATA[10.1109/CLOUD.2011.29]]></doi>

<publicationId><![CDATA[6008687]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6008687&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6008687]]></pdf>

</document>

<document>

<rank>14</rank>

<title><![CDATA[Cyberaide JavaScript: A JavaScript Commodity Grid Kit]]></title>

<authors><![CDATA[von Laszewski, G.;  Fugang Wang;  Younge, A.;  Xi He;  Zhenhua Guo;  Pierce, M.]]></authors>

<affiliations><![CDATA[Rochester Inst. of Technol., Rochester, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Java]]></term>

<term><![CDATA[Web services]]></term>

<term><![CDATA[application program interfaces]]></term>

<term><![CDATA[authoring languages]]></term>

<term><![CDATA[grid computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Graphical user interfaces]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Java]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Middleware]]></term>

<term><![CDATA[Portals]]></term>

<term><![CDATA[Resource management]]></term>

<term><![CDATA[Service oriented architecture]]></term>

<term><![CDATA[Software maintenance]]></term>

<term><![CDATA[Web services]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Grid Computing Environments Workshop, 2008. GCE '08]]></pubtitle>

<punumber><![CDATA[4729055]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[10]]></epage>

<abstract><![CDATA[In this paper, we describe a service oriented architecture and Grid abstraction framework that allows us to access Grids through JavaScript. Obviously, such a framework integrates well with other Web 2.0 technologies. The framework consists of two parts. A client Application Programming Interface (API) to access the Grid via JavaScript and a mediator service and API through which the Grid access is channeled. The framework uses commodity Web service standards and provides extended functionality such as asynchronous task management, file transfer, and workflow management based on our previous work. The availability of our framework simplifies not only the development of new services, but also the development of advanced client side Grid applications that can be accessed through Web browsers. We demonstrate this ability by providing an example that integrates a variety of useful services to be accessed through a JavaScript enabled client desktop via a Web browser. Overall, Grid developers will have another tool at their disposal that projects a simpler way to distribute and maintain cyberinfrastructure related software, while simultaneously delivering advanced interfaces and integrating social services for the scientific community.]]></abstract>

<isbn><![CDATA[978-1-4244-2860-1]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4738448]]></arnumber>

<doi><![CDATA[10.1109/GCE.2008.4738448]]></doi>

<publicationId><![CDATA[4738448]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4738448&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4738448]]></pdf>

</document>

<document>

<rank>15</rank>

<title><![CDATA[Towards Energy Aware Scheduling for Precedence Constrained Parallel Tasks in a Cluster with DVFS]]></title>

<authors><![CDATA[Lizhe Wang;  von Laszewski, G.;  Dayal, J.;  Fugang Wang]]></authors>

<affiliations><![CDATA[Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[environmental factors]]></term>

<term><![CDATA[parallel processing]]></term>

<term><![CDATA[power aware computing]]></term>

<term><![CDATA[scheduling]]></term>

<term><![CDATA[workstation clusters]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Dynamic voltage scaling]]></term>

<term><![CDATA[Energy consumption]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[High performance computing]]></term>

<term><![CDATA[Power engineering computing]]></term>

<term><![CDATA[Processor scheduling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Cluster, Cloud and Grid Computing (CCGrid), 2010 10th IEEE/ACM International Conference on]]></pubtitle>

<punumber><![CDATA[5492934]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2010]]></py>

<spage><![CDATA[368]]></spage>

<epage><![CDATA[377]]></epage>

<abstract><![CDATA[Reducing energy consumption for high end computing can bring various benefits such as, reduce operating costs, increase system reliability, and environment respect. This paper aims to develop scheduling heuristics and to present application experience for reducing power consumption of parallel tasks in a cluster with the Dynamic Voltage Frequency Scaling (DVFS) technique. In this paper, formal models are presented for precedence-constrained parallel tasks, DVFS enabled clusters, and energy consumption. This paper studies the slack time for non-critical jobs, extends their execution time and reduces the energy consumption without increasing the task's execution time as a whole. Additionally, Green Service Level Agreement is also considered in this paper. By increasing task execution time within an affordable limit, this paper develops scheduling heuristics to reduce energy consumption of a tasks execution and discusses the relationship between energy consumption and task execution time. Models and scheduling heuristics are examined with a simulation study. Test results justify the design and implementation of proposed energy aware scheduling heuristics in the paper.]]></abstract>

<isbn><![CDATA[978-1-4244-6987-1]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5493462]]></arnumber>

<doi><![CDATA[10.1109/CCGRID.2010.19]]></doi>

<publicationId><![CDATA[5493462]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5493462&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5493462]]></pdf>

</document>

<document>

<rank>16</rank>

<title><![CDATA[Quality Assured Ad Hoc Grids]]></title>

<authors><![CDATA[Amin, K.;  von Laszewski, G.;  Mikler, A.R.]]></authors>

<affiliations><![CDATA[University of North Texas]]></affiliations>

<thesaurusterms>

<term><![CDATA[Availability]]></term>

<term><![CDATA[Centralized control]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Distributed control]]></term>

<term><![CDATA[Electronic switching systems]]></term>

<term><![CDATA[Environmental management]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Java]]></term>

<term><![CDATA[Quality of service]]></term>

<term><![CDATA[Resource management]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Autonomic and Autonomous Systems and International Conference on Networking and Services, 2005. ICAS-ICNS 2005. Joint International Conference on]]></pubtitle>

<punumber><![CDATA[10434]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2005]]></py>

<spage><![CDATA[92]]></spage>

<epage><![CDATA[92]]></epage>

<abstract><![CDATA[This paper presents an integrated architecture for ad hoc Grids developed within the Java CoG Kit project. It provides an overview of the key component frameworks that collectively build the ad hoc Grid architecture. Further, it outlines a formal model that can be formally evaluated. The paper also presents an enhancement to the Java CoG Kit to address requirements posed by ad hoc Grids. It integrates into the Java CoG Kit commodity technologies such as Jxta, and ClassAds.]]></abstract>

<isbn><![CDATA[0-7695-2450-8]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1559944]]></arnumber>

<doi><![CDATA[10.1109/ICAS-ICNS.2005.82]]></doi>

<publicationId><![CDATA[1559944]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1559944&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1559944]]></pdf>

</document>

<document>

<rank>17</rank>

<title><![CDATA[A high-throughput x-ray microtomography system at the Advanced Photon Source]]></title>

<authors><![CDATA[Wang, Yuxin;  De Carlo, Francesco;  Mancini, Derrick C.;  McNulty, Ian;  Tieman, Brian;  Bresnahan, J.;  Foster, I.;  Insley, Joseph;  Lane, Peter;  von Laszewski, G.;  Kesselman, C.;  Mei-Hui Su;  Thiebaux, Marcus]]></authors>

<affiliations><![CDATA[Advanced Photon Source, Argonne National Laboratory, Argonne, Illinois]]></affiliations>

<controlledterms>

<term><![CDATA[CCD image sensors]]></term>

<term><![CDATA[X-ray microscopy]]></term>

<term><![CDATA[X-ray monochromators]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data acquisition]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[physics computing]]></term>

<term><![CDATA[pipeline processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[synchrotron radiation]]></term>

</controlledterms>

<pubtitle><![CDATA[Review of Scientific Instruments]]></pubtitle>

<punumber><![CDATA[4915264]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[AIP]]></publisher>

<volume><![CDATA[72]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[2062]]></spage>

<epage><![CDATA[2068]]></epage>

<abstract><![CDATA[A third-generation synchrotron radiation source provides enough brilliance to acquire complete tomographic data sets at 100 nm or better resolution in a few minutes. To take advantage of such high-brilliance sources at the Advanced Photon Source, we have constructed a pipelined data acquisition and reconstruction system that combines a fast detector system, high-speed data networks, and massively parallel computers to rapidly acquire the projection data and perform the reconstruction and rendering calculations. With the current setup, a data set can be obtained and reconstructed in tens of minutes. A specialized visualization computer makes rendered three-dimensional (3D) images available to the beamline users minutes after the data acquisition is completed. This system is capable of examining a large number of samples at sub-&#x3bc;m 3D resolution or studying the full 3D structure of a dynamically evolving sample on a 10 min temporal scale. In the near future, we expect to increase the spatial resolution to below 100 nm by using zone-plate x-ray focusing optics and to improve the time resolution by the use of a broadband x-ray monochromator and a faster detector system. &#xa9; 2001 American Institute of Physics.]]></abstract>

<issn><![CDATA[0034-6748]]></issn>

<arnumber><![CDATA[4998561]]></arnumber>

<doi><![CDATA[10.1063/1.1355270]]></doi>

<publicationId><![CDATA[4998561]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4998561&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4998561]]></pdf>

</document>

<document>

<rank>18</rank>

<title><![CDATA[Experiment and Workflow Management Using Cyberaide Shell]]></title>

<authors><![CDATA[von Laszewski, G.;  Younge, A.;  Xi He;  Mahinthakumar, K.;  Lizhe Wang]]></authors>

<affiliations><![CDATA[Service Oriented Cyberinfrastracture Lab., Rochester Inst. of Technol., Rochester, NY]]></affiliations>

<controlledterms>

<term><![CDATA[application program interfaces]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[middleware]]></term>

<term><![CDATA[natural sciences computing]]></term>

<term><![CDATA[workflow management software]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Energy management]]></term>

<term><![CDATA[Environmental management]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Middleware]]></term>

<term><![CDATA[Operating systems]]></term>

<term><![CDATA[Resource management]]></term>

<term><![CDATA[Technology management]]></term>

<term><![CDATA[USA Councils]]></term>

<term><![CDATA[Usability]]></term>

<term><![CDATA[Utility programs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Cluster Computing and the Grid, 2009. CCGRID '09. 9th IEEE/ACM International Symposium on]]></pubtitle>

<punumber><![CDATA[5071832]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2009]]></py>

<spage><![CDATA[568]]></spage>

<epage><![CDATA[573]]></epage>

<abstract><![CDATA[In recent years the power of Grid computing has grown exponentially through the development of advanced middleware systems. While usage has increased, the penetration of Grid computing in the scientific community has been less than expected by some. This is due to a steep learning curve and high entry barrier that limit the use of Grid computing and advanced cyberinfrastructure. In order for the scientists to focus on actual scientific tasks, specialized tools and services need to be developed to ease the integration of complex middleware. Our solution is Cyberaide Shell, an advanced but simple to use systemshell which provides access to the powerful cyberinfrastructure available today. Cyberaide Shell provides a dynamic interface that allows access to complex cyberinfrastructure in an easy and intuitive fashion on an ad-hoc basis. This is accomplished by abstracting the complexities of resource, task, and application management through a scriptable command line interface. Through a service integration mechanism, the shellpsilas functionality is exposed to a wide variety of frameworks and programming languages. Cyberaide Shell includes specialized experiment management and workflow commands that, with the scriptable nature of a shell, provide a set of services which where previously unavailable. The usability of Cyberaide Shell is demonstrated using a Water Threat Management application deployed on the TeraGrid.]]></abstract>

<isbn><![CDATA[978-1-4244-3935-5]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5071923]]></arnumber>

<doi><![CDATA[10.1109/CCGRID.2009.66]]></doi>

<publicationId><![CDATA[5071923]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5071923&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5071923]]></pdf>

</document>

<document>

<rank>19</rank>

<title><![CDATA[On the parallelization of blocked LU factorization algorithms on distributed memory architectures]]></title>

<authors><![CDATA[von Laszewski, G.;  Parashar, M.;  Mohamed, A.G.;  Fox, G.C.]]></authors>

<affiliations><![CDATA[Syracuse Univ., NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[distributed memory systems]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[parallel algorithms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Contracts]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Government]]></term>

<term><![CDATA[Hypercubes]]></term>

<term><![CDATA[Memory architecture]]></term>

<term><![CDATA[Parallel architectures]]></term>

<term><![CDATA[Registers]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Supercomputing '92., Proceedings]]></pubtitle>

<punumber><![CDATA[390]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[1992]]></py>

<spage><![CDATA[170]]></spage>

<epage><![CDATA[179]]></epage>

<abstract><![CDATA[The authors present the parallelization of blocked algorithms for LU factorization. They isolate problems inherent in sequential blocked algorithms and provide approaches to overcome them on distributed memory architectures. The performances of the parallelized versions of three blocked algorithms suited to column oriented Fortran are compared. Experiments are performed on the iPSC/860 hypercube. It is shown that it is not intuitively clear which algorithm might perform best on a given architecture; this is dependent on the problem size and the number of available parameters]]></abstract>

<isbn><![CDATA[0-8186-2630-5]]></isbn>

<arnumber><![CDATA[236696]]></arnumber>

<doi><![CDATA[10.1109/SUPERC.1992.236696]]></doi>

<publicationId><![CDATA[236696]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=236696&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=236696]]></pdf>

</document>

<document>

<rank>20</rank>

<title><![CDATA[Power Aware Scheduling for Parallel Tasks via Task Clustering]]></title>

<authors><![CDATA[Lizhe Wang;  Jie Tao;  von Laszewski, G.;  Dan Chen]]></authors>

<affiliations><![CDATA[Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[energy consumption]]></term>

<term><![CDATA[parallel processing]]></term>

<term><![CDATA[power aware computing]]></term>

<term><![CDATA[scheduling]]></term>

<term><![CDATA[simulation]]></term>

<term><![CDATA[task analysis]]></term>

</controlledterms>

<pubtitle><![CDATA[Parallel and Distributed Systems (ICPADS), 2010 IEEE 16th International Conference on]]></pubtitle>

<punumber><![CDATA[5692856]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2010]]></py>

<spage><![CDATA[629]]></spage>

<epage><![CDATA[634]]></epage>

<abstract><![CDATA[It has been widely known that various benefits can be achieved by reducing energy consumption for high end computing. This paper aims to develop power aware scheduling heuristics for parallel tasks in a cluster with the DVFS technique. In this paper, formal models are presented for precedence-constrained parallel tasks, DVFS enabled clusters, and energy consumption. This paper studies the slack time for non-critical jobs, extends their execution time and reduces the energy consumption without increasing the task's execution time as a whole. This paper develops a power aware task clustering algorithm for parallel task scheduling Simulation results justify the design and implementation of proposed energy aware scheduling heuristics in the paper.]]></abstract>

<issn><![CDATA[1521-9097]]></issn>

<isbn><![CDATA[978-1-4244-9727-0]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5695657]]></arnumber>

<doi><![CDATA[10.1109/ICPADS.2010.128]]></doi>

<publicationId><![CDATA[5695657]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5695657&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5695657]]></pdf>

</document>

<document>

<rank>21</rank>

<title><![CDATA[Swift: Fast, Reliable, Loosely Coupled Parallel Computation]]></title>

<authors><![CDATA[Yong Zhao;  Hategan, M.;  Clifford, B.;  Foster, I.;  von Laszewski, G.;  Nefedova, V.;  Raicu, I.;  Stef-Praun, T.;  Wilde, M.]]></authors>

<affiliations><![CDATA[Univ. of Chicago, Chicago]]></affiliations>

<controlledterms>

<term><![CDATA[formal specification]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[software reliability]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Data systems]]></term>

<term><![CDATA[Distributed computing]]></term>

<term><![CDATA[File systems]]></term>

<term><![CDATA[High performance computing]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Magnetic analysis]]></term>

<term><![CDATA[Mathematics]]></term>

<term><![CDATA[Power system reliability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Services, 2007 IEEE Congress on]]></pubtitle>

<punumber><![CDATA[4278748]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2007]]></py>

<spage><![CDATA[199]]></spage>

<epage><![CDATA[206]]></epage>

<abstract><![CDATA[We present Swift, a system that combines a novel scripting language called SwiftScript with a powerful runtime system based on CoG Karajan, Falkon, and Globus to allow for the concise specification, and reliable and efficient execution, of large loosely coupled computations. Swift adopts and adapts ideas first explored in the GriPhyN virtual data system, improving on that system in many regards. We describe the SwiftScript language and its use of XDTM to describe the logical structure of complex file system structures. We also present the Swift runtime system and its use of CoG Karajan, Falkon, and Globus services to dispatch and manage the execution of many tasks in parallel and grid environments. We describe application experiences and performance experiments that quantify the cost of Swift operations.]]></abstract>

<isbn><![CDATA[978-0-7695-2926-4]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4278797]]></arnumber>

<doi><![CDATA[10.1109/SERVICES.2007.63]]></doi>

<publicationId><![CDATA[4278797]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4278797&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4278797]]></pdf>

</document>

<document>

<rank>22</rank>

<title><![CDATA[Thermal aware workload scheduling with backfilling for green data centers]]></title>

<authors><![CDATA[Lizhe Wang;  von Laszewski, G.;  Dayal, J.;  Furlani, T.R.]]></authors>

<affiliations><![CDATA[Service Oriented Cyberinfrastructure Lab., Rochester Inst. of Technol., Rochester, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer centres]]></term>

<term><![CDATA[cooling]]></term>

<term><![CDATA[heat transfer]]></term>

<term><![CDATA[power consumption]]></term>

<term><![CDATA[scheduling]]></term>

<term><![CDATA[thermal analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Cooling]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Energy consumption]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Heat transfer]]></term>

<term><![CDATA[Resource management]]></term>

<term><![CDATA[Scheduling algorithm]]></term>

<term><![CDATA[Temperature]]></term>

<term><![CDATA[Thermal management]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Performance Computing and Communications Conference (IPCCC), 2009 IEEE 28th International]]></pubtitle>

<punumber><![CDATA[5398688]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2009]]></py>

<spage><![CDATA[289]]></spage>

<epage><![CDATA[296]]></epage>

<abstract><![CDATA[Data centers now play an important role in modern IT infrastructures. Related research has shown that the energy consumption for data center cooling systems has recently increased significantly. There is also strong evidence to show that high temperatures with in a data center will lead to higher hardware failure rates and thus an increase in maintenance costs. This paper devotes itself in the field of thermal aware resource management for data centers. This paper proposes an analytical model, which describes data center resources with heat transfer properties and workloads with thermal features. Then a thermal aware task scheduling algorithm with backfilling is presented which aims to reduce power consumption and temperatures in a data center. A simulation study is carried out to evaluate the performance of the algorithm. Simulation results show that our algorithm can significantly reduce temperatures in data centers by introducing endurable decline in performance.]]></abstract>

<issn><![CDATA[1097-2641]]></issn>

<isbn><![CDATA[978-1-4244-5737-3]]></isbn>

<arnumber><![CDATA[5403821]]></arnumber>

<doi><![CDATA[10.1109/PCCC.2009.5403821]]></doi>

<publicationId><![CDATA[5403821]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5403821&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5403821]]></pdf>

</document>

<document>

<rank>23</rank>

<title><![CDATA[Flexible framework for commodity FPGA cluster computing]]></title>

<authors><![CDATA[Espenshade, J.;  Lukowiak, M.;  Shaaban, M.;  von Laszewski, G.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Eng., Rochester Inst. of Technol., Rochester, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[field programmable gate arrays]]></term>

<term><![CDATA[hardware-software codesign]]></term>

<term><![CDATA[message passing]]></term>

<term><![CDATA[parallel programming]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Energy management]]></term>

<term><![CDATA[Field programmable gate arrays]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[High performance computing]]></term>

<term><![CDATA[Linux]]></term>

<term><![CDATA[Software tools]]></term>

<term><![CDATA[Standards development]]></term>

<term><![CDATA[Technology management]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Field-Programmable Technology, 2009. FPT 2009. International Conference on]]></pubtitle>

<punumber><![CDATA[5367680]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2009]]></py>

<spage><![CDATA[465]]></spage>

<epage><![CDATA[471]]></epage>

<abstract><![CDATA[With falling costs and successful demonstrations of performance, FPGAs have become a prime candidate for use in high performance computing. However, the use of FPGA technology in clustered environments has largely been limited to commercial and/or proprietary designs that require developers to learn new programming models and software tools. In this paper, a framework is presented which enables development of parallel programs across application-specific reconfigurable hardware using simple hardware interface abstractions and standard MPI application structure. This approach leverages commodity technologies including embedded Linux running on hardwired PowerPC processors to manage communication such that each hardware acceleration unit can function as a fully MPI-2 compatible node. The implied hardware/software design and programming model are discussed and an application case study is presented to demonstrate functionality and elucidate platform benefits through performance analysis.]]></abstract>

<isbn><![CDATA[978-1-4244-4375-8]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5377649]]></arnumber>

<doi><![CDATA[10.1109/FPT.2009.5377649]]></doi>

<publicationId><![CDATA[5377649]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5377649&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5377649]]></pdf>

</document>

<document>

<rank>24</rank>

<title><![CDATA[A Repository Service for Grid Workflow Components]]></title>

<authors><![CDATA[von Laszewski, G.;  Kodeboyina, D.]]></authors>

<affiliations><![CDATA[Argonne Nat. Lab., IL]]></affiliations>

<controlledterms>

<term><![CDATA[Java]]></term>

<term><![CDATA[ad hoc networks]]></term>

<term><![CDATA[grid computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Availability]]></term>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Conference management]]></term>

<term><![CDATA[Independent component analysis]]></term>

<term><![CDATA[Java]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Network servers]]></term>

<term><![CDATA[Peer to peer computing]]></term>

<term><![CDATA[Runtime]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Autonomic and Autonomous Systems and International Conference on Networking and Services, 2005. ICAS-ICNS 2005. Joint International Conference on]]></pubtitle>

<punumber><![CDATA[10434]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2005]]></py>

<spage><![CDATA[84]]></spage>

<epage><![CDATA[84]]></epage>

<abstract><![CDATA[As part of the Java CoG kit we have defined a sophisticated workflow framework. This workflow framework projects an integrated approach towards executing tasks in grid and non-grid environments. One of the services needed is a convenient service to store, retrieve, and modify workflow components defined by the community similar to systems such as the comprehensive perl archive network. The availability of such a service will not only allow the definition of components useful for the greater grid community, but it will also be possible that it can be reused to support dynamically changing workflows managed by collaborative groups. In this paper, we present a simple extensible framework to design, build, and deploy a workflow repository service. This repository is intended to be used in ad-hoc grids or in community grids]]></abstract>

<isbn><![CDATA[0-7695-2450-8]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1559936]]></arnumber>

<doi><![CDATA[10.1109/ICAS-ICNS.2005.8]]></doi>

<publicationId><![CDATA[1559936]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1559936&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1559936]]></pdf>

</document>

<document>

<rank>25</rank>

<title><![CDATA[QoS support for high-performance scientific Grid applications]]></title>

<authors><![CDATA[Al-Ali, R.;  von Laszewski, G.;  Amin, K.;  Hategan, M.;  Rana, O.;  Walker, D.;  Zaluzec, N.]]></authors>

<affiliations><![CDATA[Argonne Nat. Lab., IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[natural sciences computing]]></term>

<term><![CDATA[quality of service]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Electron microscopy]]></term>

<term><![CDATA[Environmental management]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Quality management]]></term>

<term><![CDATA[Quality of service]]></term>

<term><![CDATA[Resource management]]></term>

<term><![CDATA[Scheduling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Cluster Computing and the Grid, 2004. CCGrid 2004. IEEE International Symposium on]]></pubtitle>

<punumber><![CDATA[9282]]></punumber>

<pubtype><![CDATA[Conference Publications]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<py><![CDATA[2004]]></py>

<spage><![CDATA[134]]></spage>

<epage><![CDATA[143]]></epage>

<abstract><![CDATA[The Grid approach provides the ability to access and use distributed resources as part of virtual organizations. The emerging Grid infrastructure gives rise to a class of scientific applications and services to support collaborative and distributed resource-sharing requirements as part of teleimmersion, visualization, and simulation services. Because such applications operate in a collaborative mode, data must be stored and delivered in timely manner to meet deadlines. Hence, this class of applications has stringent real-time constraints and quality-of-service (QoS) requirements. A QoS management approach is required to orchestrate and guarantee the interaction between such applications and services. In this paper we discuss the design and prototype implementation of a QoS system and show how we enable Grid applications to become QoS compliant. We validate this approach through a case study of nanomaterials. Our approach enhances the current Open Grid Services Architecture. We demonstrate the usefulness of the approach on a nanomaterials application.]]></abstract>

<isbn><![CDATA[0-7803-8430-X]]></isbn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1336559]]></arnumber>

<doi><![CDATA[10.1109/CCGrid.2004.1336559]]></doi>

<publicationId><![CDATA[1336559]]></publicationId>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1336559&contentType=Conference+Publications]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1336559]]></pdf>

</document>

</root>

